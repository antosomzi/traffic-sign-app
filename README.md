# Application Flask + Celery + Redis - Pipeline ML

Web application for uploading, validating, and asynchronously processing recordings through an ML pipeline.

## ğŸ—ï¸ Architecture

- **Flask**: Web interface, upload, extraction and validation of ZIP archives
- **Redis**: Message broker for Celery task queue
- **Celery**: Asynchronous worker for ML pipeline processing
- **Shared filesystem**: Storage for uploads and results

## ğŸ“ Project Structure

```
app/
â”œâ”€â”€ app.py                      # Main Flask application
â”œâ”€â”€ celery_app.py               # Celery configuration
â”œâ”€â”€ tasks.py                    # Asynchronous tasks
â”œâ”€â”€ simulate_pipeline.sh        # Pipeline simulation script
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # Environment variables (not in git)
â”œâ”€â”€ DEPLOYMENT.md               # Deployment guide for EC2
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ upload.html            # Upload interface
â”‚   â””â”€â”€ status.html            # Status tracking
â””â”€â”€ README.md                  # This file
```

## ğŸš€ Local Installation

### 1. Clone the repository

```bash
git clone <your-repo-url>
cd app
```

### 2. Create virtual environment

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Python dependencies

```bash
pip install -r requirements.txt
```

### 4. Install and start Redis

**On macOS (with Homebrew):**
```bash
brew install redis
redis-server
```

**On Ubuntu/Debian:**
```bash
sudo apt-get install redis-server
sudo systemctl start redis
```

**On Windows:**
- Download Redis from https://redis.io/download
- Or use WSL2

### 5. Configure environment variables (optional for local dev)

```bash
# Create .env file (already exists with defaults)
cp .env.example .env  # If you want to customize
```

For local development, you can run without password. For production, see `DEPLOYMENT.md`.

### 6. Make the simulation script executable

```bash
chmod +x simulate_pipeline.sh
```

## ğŸ¯ DÃ©marrage

Ouvrez **3 terminaux** et exÃ©cutez les commandes suivantes :

### Terminal 1 - Redis
```bash
redis-server
```

### Terminal 2 - Celery Worker
```bash
celery -A tasks worker --loglevel=INFO
```

### Terminal 3 - Flask App
```bash
python app.py
```

L'application sera accessible sur : **http://localhost:5000**

## ğŸ“ Utilisation

### 1. Upload d'un enregistrement

1. AccÃ©dez Ã  `http://localhost:5000`
2. Glissez-dÃ©posez ou sÃ©lectionnez un fichier ZIP
3. Cliquez sur "TÃ©lÃ©charger et valider"
4. L'application va :
   - Extraire le ZIP
   - Valider la structure
   - Ajouter une tÃ¢che Celery si valide

### 2. Suivi des traitements

- Cliquez sur "Voir les statuts des enregistrements"
- Vous verrez tous les enregistrements avec leur statut
- La page se rafraÃ®chit automatiquement toutes les 10 secondes

### 3. TÃ©lÃ©chargement des rÃ©sultats

- Une fois le traitement terminÃ©, un bouton "TÃ©lÃ©charger les rÃ©sultats" apparaÃ®t
- Le tÃ©lÃ©chargement contient les fichiers `supports.csv` et `signs.csv`

## ğŸ—‚ï¸ Structure de donnÃ©es attendue

```
<recording_id>/
â””â”€â”€ <device_id>/
    â””â”€â”€ <imei_folder>/
        â”œâ”€â”€ acceleration/
        â”‚   â””â”€â”€ <recording_id>_acc.csv
        â”œâ”€â”€ calibration/
        â”‚   â””â”€â”€ *_calibration.csv (au moins 1)
        â”œâ”€â”€ camera/
        â”‚   â”œâ”€â”€ <recording_id>_cam_<recording_id>.mp4
        â”‚   â””â”€â”€ camera_params.csv
        â”œâ”€â”€ location/
        â”‚   â”œâ”€â”€ <recording_id>_loc.csv
        â”‚   â””â”€â”€ <recording_id>_loc_cleaned.csv
        â””â”€â”€ processed/
            â”œâ”€â”€ <recording_id>_processed_acc.csv
            â””â”€â”€ <recording_id>_processed_loc.csv
```

## ğŸ“Š Pipeline de traitement

La pipeline comporte 8 Ã©tapes :

1. **s0_detection** - DÃ©tection initiale
2. **s1_small_sign_filter** - Filtrage des petits panneaux
3. **s2_tracking** - Suivi des objets
4. **s3_small_track_filter** - Filtrage des petites trajectoires
5. **s4_classification** - Classification des panneaux
6. **s5_frames_gps_coordinates_extraction** - Extraction des coordonnÃ©es GPS
7. **s6_localization** - Localisation
8. **s7_export_csv** - Export CSV final

## ğŸ”§ Configuration

Les chemins par dÃ©faut sont configurÃ©s pour EC2 dans `/home/ec2-user/`:

- `uploads/` - Fichiers uploadÃ©s
- `temp_extracts/` - Extraction temporaire
- `recordings/` - Enregistrements validÃ©s

Pour modifier, Ã©ditez les constantes dans `app.py` et `tasks.py`.

## ğŸ› DÃ©pannage

### Redis ne dÃ©marre pas
```bash
# VÃ©rifier si Redis tourne
redis-cli ping
# Devrait retourner "PONG"
```

### Celery ne trouve pas les tÃ¢ches
```bash
# VÃ©rifier que vous Ãªtes dans le bon rÃ©pertoire
celery -A tasks inspect active
```

### ProblÃ¨mes de permissions
```bash
# Donner les permissions au script
chmod +x simulate_pipeline.sh
```

## ğŸ“Œ Notes importantes

- La simulation de pipeline prend environ **40 secondes** (5 sec par Ã©tape)
- Le worker Celery traite les tÃ¢ches **sÃ©quentiellement**
- Les fichiers ZIP sont supprimÃ©s aprÃ¨s extraction rÃ©ussie
- En cas d'erreur de validation, tout est nettoyÃ© automatiquement

## ğŸ” SÃ©curitÃ©

- Protection contre les attaques **ZipSlip**
- Validation stricte de la structure des fichiers
- Limite de taille : **8 GB**
- Types de fichiers autorisÃ©s : ZIP, TAR, TAR.GZ, TGZ

## ğŸ“ˆ Ã‰volutions possibles

- [ ] Ajouter plusieurs workers Celery pour le parallÃ©lisme
- [ ] ImplÃ©menter l'authentification utilisateur
- [ ] Ajouter des notifications par email
- [ ] Logger les Ã©vÃ©nements dans une base de donnÃ©es
- [ ] Ajouter un monitoring avec Flower (interface Celery)
