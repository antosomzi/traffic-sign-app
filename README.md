# Application Flask + Celery + Redis - Pipeline ML

Web application for uploading, validating, and asynchronously processing recordings through an ML pipeline.

## ğŸ—ï¸ Architecture

- **Flask**: Web interface, upload, extraction and validation of ZIP archives
- **Redis**: 
  - Message broker for Celery task queue
  - Shared state storage for extraction progress (across Gunicorn workers)
- **Celery**: Asynchronous worker for ML pipeline processing
- **Gunicorn**: Production WSGI server with 4 worker processes
- **Shared filesystem**: Storage for uploads and results

### Multi-Worker Architecture

The application uses **Gunicorn with 4 workers** for production. Since each worker has its own memory space, Redis is used to share the extraction progress state between workers:

```
Request 1 (Upload) â†’ Worker #1 â†’ Creates extraction progress in Redis
Request 2 (Status) â†’ Worker #3 â†’ Reads extraction progress from Redis âœ…
Request 3 (Status) â†’ Worker #2 â†’ Reads extraction progress from Redis âœ…
```

Without Redis, each worker would have its own `extraction_progress = {}` dictionary, causing 404 errors when different workers handle the status requests.

## ğŸ“ Project Structure

```
app/
â”œâ”€â”€ app.py                      # Main Flask application
â”œâ”€â”€ celery_app.py               # Celery configuration
â”œâ”€â”€ tasks.py                    # Asynchronous tasks
â”œâ”€â”€ simulate_pipeline.sh        # Pipeline simulation script
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # Environment variables (not in git)
â”œâ”€â”€ DEPLOYMENT.md               # Deployment guide for EC2
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ upload.html            # Upload interface
â”‚   â””â”€â”€ status.html            # Status tracking
â””â”€â”€ README.md                  # This file
```

## ğŸš€ Local Installation

### 1. Clone the repository

```bash
git clone <your-repo-url>
cd app
```

### 2. Create virtual environment

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Python dependencies

```bash
pip install -r requirements.txt
```

### 4. Install and start Redis

**On macOS (with Homebrew):**
```bash
brew install redis
redis-server
```

**On Ubuntu/Debian:**
```bash
sudo apt-get install redis-server
sudo systemctl start redis
```

**On Windows:**
- Download Redis from https://redis.io/download
- Or use WSL2

### 5. Configure environment variables (optional for local dev)

```bash
# Create .env file (already exists with defaults)
cp .env.example .env  # If you want to customize
```

For local development, you can run without password. For production, see `DEPLOYMENT.md`.

### 6. Make the simulation script executable

```bash
chmod +x simulate_pipeline.sh
```

## ğŸ¯ DÃ©marrage

Ouvrez **3 terminaux** et exÃ©cutez les commandes suivantes :

### Terminal 1 - Redis
```bash
redis-server
```

### Terminal 2 - Celery Worker
```bash
celery -A tasks worker --loglevel=INFO
```

### Terminal 3 - Flask App
```bash
python app.py
```

L'application sera accessible sur : **http://localhost:5000**

## ğŸ“ Utilisation

### 1. Upload d'un enregistrement

1. AccÃ©dez Ã  `http://localhost:5000`
2. Glissez-dÃ©posez ou sÃ©lectionnez un fichier ZIP
3. Cliquez sur "TÃ©lÃ©charger et valider"
4. L'application va :
   - Extraire le ZIP
   - Valider la structure
   - Ajouter une tÃ¢che Celery si valide

### 2. Suivi des traitements

- Cliquez sur "Voir les statuts des enregistrements"
- Vous verrez tous les enregistrements avec leur statut
- La page se rafraÃ®chit automatiquement toutes les 10 secondes

### 3. TÃ©lÃ©chargement des rÃ©sultats

- Une fois le traitement terminÃ©, un bouton "TÃ©lÃ©charger les rÃ©sultats" apparaÃ®t
- Le tÃ©lÃ©chargement contient les fichiers `supports.csv` et `signs.csv`

## ğŸ—‚ï¸ Structure de donnÃ©es attendue

```
<recording_id>/
â””â”€â”€ <device_id>/
    â””â”€â”€ <imei_folder>/
        â”œâ”€â”€ acceleration/
        â”‚   â””â”€â”€ <recording_id>_acc.csv
        â”œâ”€â”€ calibration/
        â”‚   â””â”€â”€ *_calibration.csv (au moins 1)
        â”œâ”€â”€ camera/
        â”‚   â”œâ”€â”€ <recording_id>_cam_<recording_id>.mp4
        â”‚   â””â”€â”€ camera_params.csv
        â”œâ”€â”€ location/
        â”‚   â”œâ”€â”€ <recording_id>_loc.csv
        â”‚   â””â”€â”€ <recording_id>_loc_cleaned.csv
        â””â”€â”€ processed/
            â”œâ”€â”€ <recording_id>_processed_acc.csv
            â””â”€â”€ <recording_id>_processed_loc.csv
```

## ğŸ“Š Pipeline de traitement

La pipeline comporte 8 Ã©tapes :

1. **s0_detection** - DÃ©tection initiale
2. **s1_small_sign_filter** - Filtrage des petits panneaux
3. **s2_tracking** - Suivi des objets
4. **s3_small_track_filter** - Filtrage des petites trajectoires
5. **s4_classification** - Classification des panneaux
6. **s5_frames_gps_coordinates_extraction** - Extraction des coordonnÃ©es GPS
7. **s6_localization** - Localisation
8. **s7_export_csv** - Export CSV final

## ğŸ”§ Configuration

### Redis for Extraction Progress

Redis stores extraction progress as JSON strings with the following structure:

**Redis Key Format:**
```
extraction:<job_id>
```

**Value (JSON):**
```json
{
  "status": "running",           // "queued", "running", "done", "error"
  "total_files": 250,             // Total files in ZIP
  "extracted_files": 120,         // Files extracted so far
  "extract_size": 1024000,        // Final size in bytes (null until done)
  "recording_id": "2024_05_...",  // Recording ID (null until done)
  "error_msg": null,              // Error message if status="error"
  "error_details": null           // Detailed error info (dict)
}
```

**TTL (Time To Live):** 1 hour (3600 seconds) - Redis automatically deletes old entries

**Update Frequency:** Progress is updated every 10 files during extraction to optimize performance.

### Helper Functions

```python
# Read from Redis (JSON string â†’ Python dict)
prog = get_extraction_progress(job_id)

# Write to Redis (Python dict â†’ JSON string)
set_extraction_progress(job_id, progress_dict)

# Modify in Python (standard dict operations)
prog["status"] = "running"
prog["extracted_files"] += 1
```

### File Paths

Les chemins par dÃ©faut sont configurÃ©s pour EC2 dans `/home/ec2-user/`:

- `uploads/` - Fichiers uploadÃ©s
- `temp_extracts/` - Extraction temporaire
- `recordings/` - Enregistrements validÃ©s

Pour modifier, Ã©ditez les constantes dans `app.py` et `tasks.py`.

## ğŸ› DÃ©pannage

### Redis ne dÃ©marre pas
```bash
# VÃ©rifier si Redis tourne
redis-cli ping
# Devrait retourner "PONG"

# Sur EC2 avec mot de passe
redis6-cli -a Moulines1 ping
```

### VÃ©rifier les donnÃ©es Redis
```bash
# Voir toutes les clÃ©s extraction
redis6-cli -a Moulines1 KEYS "extraction:*"

# Voir le contenu d'une clÃ©
redis6-cli -a Moulines1 GET "extraction:abc123..."

# Voir le temps restant avant expiration
redis6-cli -a Moulines1 TTL "extraction:abc123..."

# Supprimer une clÃ© manuellement
redis6-cli -a Moulines1 DEL "extraction:abc123..."

# Vider toute la base Redis (ATTENTION!)
redis6-cli -a Moulines1 FLUSHDB
```

### ProblÃ¨me de barre de progression bloquÃ©e

Si la barre de progression reste Ã  0% puis saute Ã  100% :
- **Cause**: Le dictionnaire `extraction_progress` n'est pas partagÃ© entre workers Gunicorn
- **Solution**: Redis est maintenant utilisÃ© pour partager l'Ã©tat entre workers âœ…

### Celery ne trouve pas les tÃ¢ches
```bash
# VÃ©rifier que vous Ãªtes dans le bon rÃ©pertoire
celery -A celery_app inspect active

# VÃ©rifier que tasks.py est bien importÃ© dans celery_app.py
grep "import tasks" celery_app.py
```

### Erreur "Command 'bash' not found" (Celery)

Si Celery ne trouve pas `bash` lors de l'exÃ©cution de `simulate_pipeline.sh` :
- **Cause**: La variable `PATH` n'est pas dÃ©finie dans le service systemd
- **Solution**: Ajouter `Environment="PATH=/usr/bin:/bin"` dans `/etc/systemd/system/celery-worker.service`

```ini
[Service]
Environment="PATH=/home/ec2-user/app/venv/bin:/usr/local/bin:/usr/bin:/bin"
```

### ProblÃ¨mes de permissions
```bash
# Donner les permissions au script
chmod +x simulate_pipeline.sh
```

## ğŸ“Œ Notes importantes

- La simulation de pipeline prend environ **40 secondes** (5 sec par Ã©tape)
- Le worker Celery traite les tÃ¢ches **sÃ©quentiellement**
- Les fichiers ZIP sont supprimÃ©s aprÃ¨s extraction rÃ©ussie
- En cas d'erreur de validation, tout est nettoyÃ© automatiquement
- **Redis stocke les progrÃ¨s d'extraction pendant 1 heure** (TTL = 3600s)
- **Gunicorn utilise 4 workers** en production pour gÃ©rer les requÃªtes simultanÃ©es
- **La barre de progression se met Ã  jour toutes les 10 fichiers** pour optimiser les performances
- **Le frontend poll le status toutes les 300ms** pour une progression fluide

### Pourquoi Redis pour l'extraction progress ?

Avec Gunicorn (4 workers), chaque worker a sa propre mÃ©moire. Sans Redis :
- Worker #1 extrait le ZIP et stocke `extraction_progress[job_id]` dans **sa mÃ©moire**
- Worker #2 reÃ§oit une requÃªte `/extract_status/<job_id>` mais ne voit **rien** dans sa mÃ©moire â†’ 404 !

Avec Redis :
- Worker #1 Ã©crit dans Redis : `SET extraction:job_id {...}`
- Worker #2, #3, #4 lisent depuis Redis : `GET extraction:job_id` â†’ âœ… PartagÃ© !

## ğŸ” SÃ©curitÃ©

- Protection contre les attaques **ZipSlip**
- Validation stricte de la structure des fichiers
- Limite de taille : **8 GB**
- Types de fichiers autorisÃ©s : ZIP, TAR, TAR.GZ, TGZ

## ğŸ“ˆ Ã‰volutions possibles

- [ ] Ajouter plusieurs workers Celery pour le parallÃ©lisme
- [ ] ImplÃ©menter l'authentification utilisateur
- [ ] Ajouter des notifications par email
- [ ] Logger les Ã©vÃ©nements dans une base de donnÃ©es
- [ ] Ajouter un monitoring avec Flower (interface Celery)
