# Traffic Sign ML Pipeline

Web application for uploading, validating, and asynchronously processing traffic sign recordings through a machine learning pipeline.

## ğŸ“‘ Table of Contents

- [Architecture](#-architecture)
- [Features](#-features)
- [Project Structure](#-project-structure)
- [Installation](#-installation)
- [Usage](#-usage)
- [Expected Data Structure](#-expected-data-structure)
- [Configuration](#-configuration)
- [Security](#-security)
- [Technology Stack](#-technology-stack)

## ğŸ—ï¸ Architecture

**3-Tier Asynchronous Processing System:**

- **Flask**: Web interface for file upload, validation, and result delivery
- **Redis**: 
  - Message broker for Celery task queue
  - Shared state storage for extraction progress (critical for multi-worker Gunicorn)
- **Celery**: Asynchronous worker for ML pipeline processing
- **Gunicorn**: Production WSGI server with 4 worker processes

### Multi-Worker Architecture

Production uses **Gunicorn with 4 workers**. Since each worker has separate memory, Redis ensures extraction progress is shared across all workers:

```
Request 1 (Upload) â†’ Worker #1 â†’ Stores progress in Redis
Request 2 (Status) â†’ Worker #3 â†’ Reads progress from Redis âœ…
Request 3 (Status) â†’ Worker #2 â†’ Reads progress from Redis âœ…
```

Without Redis, status checks would return 404 when handled by different workers.

### Execution Modes

Toggle via `USE_GPU_INSTANCE` environment variable:
- **Local mode** (default): Runs pipeline on the same instance
- **GPU mode**: Launches AWS EC2 GPU instance, executes via SSH, auto-stops after completion

For detailed deployment and GPU configuration, see **[DEPLOYMENT.md](DEPLOYMENT.md)**.

## âœ¨ Features

- **Drag-and-drop file upload** with real-time progress tracking
- **Strict validation** of recording structure before processing
- **Asynchronous processing** with status monitoring
- **Automatic cleanup** of macOS system files (`__MACOSX/`, `.DS_Store`)
- **Atomic operations** (extract â†’ validate â†’ move)
- **Multi-worker safe** progress tracking via Redis
- **GPU instance orchestration** for compute-intensive ML tasks
- **Downloadable results** (CSV exports of detected traffic signs)

## ğŸ“ Project Structure

```
app/
â”œâ”€â”€ app.py                      # Flask application & routes
â”œâ”€â”€ celery_app.py               # Celery configuration
â”œâ”€â”€ tasks.py                    # Async pipeline tasks
â”œâ”€â”€ gpu_pipeline_runner.py      # GPU instance pipeline execution
â”œâ”€â”€ gpu_config.py               # AWS GPU configuration
â”œâ”€â”€ simulate_pipeline.sh        # Pipeline simulation script
â”œâ”€â”€ start_gunicorn.sh           # Production server startup
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # Environment variables
â”œâ”€â”€ DEPLOYMENT.md               # EC2 deployment guide
â”œâ”€â”€ EC2_GPU_CONFIG.md           # GPU instance setup
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ upload.html            # Upload interface
â”‚   â””â”€â”€ status.html            # Status monitoring
â”œâ”€â”€ recordings/                 # Validated recordings
â”œâ”€â”€ uploads/                    # Uploaded files
â””â”€â”€ temp_extracts/             # Temporary extraction folder
```

## ğŸš€ Installation

### Prerequisites

- Python 3.11+
- Redis 6+
- Git

### Local Setup

**1. Clone the repository**
```bash
git clone <repository-url>
cd app
```

**2. Create virtual environment**
```bash
python3 -m venv venv
source venv/bin/activate
```

**3. Install dependencies**
```bash
pip install -r requirements.txt
```

**4. Install and start Redis**

macOS (Homebrew):
```bash
brew install redis
redis-server
```

Ubuntu/Debian:
```bash
sudo apt-get install redis-server
sudo systemctl start redis
```

**5. Make scripts executable**
```bash
chmod +x simulate_pipeline.sh start_gunicorn.sh
```

### Running Locally (Development)

Open **3 terminals**:

```bash
# Terminal 1 - Redis
redis-server

# Terminal 2 - Celery Worker
celery -A tasks worker --loglevel=INFO

# Terminal 3 - Flask App
python app.py
```

Access the application at: **http://localhost:5000**

## ğŸ“ Usage

### 1. Upload Recording

1. Navigate to `http://localhost:5000`
2. Drag-and-drop or select a ZIP file
3. Click "Upload and Validate"
4. The system will:
   - Extract the archive
   - Validate the folder structure
   - Queue a Celery task if valid

### 2. Monitor Processing

- Click "View Recording Status"
- Track all recordings and their pipeline progress
- Page auto-refreshes every 10 seconds

### 3. Download Results

- Once processing is complete, click "Download Results"
- Downloads a ZIP containing `supports.csv` and `signs.csv`

## ğŸ—‚ï¸ Expected Data Structure

The uploaded ZIP must contain exactly one root folder with the following structure:

```
recording_id/
  â””â”€â”€ device_id/
      â””â”€â”€ imei_folder/
          â”œâ”€â”€ acceleration/
          â”‚     â””â”€â”€ recording_id_acc.csv
          â”œâ”€â”€ calibration/
          â”‚     â””â”€â”€ *_calibration.csv (at least 1 file)
          â”œâ”€â”€ camera/
          â”‚     â”œâ”€â”€ recording_id_cam_recording_id.mp4
          â”‚     â””â”€â”€ camera_params.csv
          â”œâ”€â”€ location/
          â”‚     â”œâ”€â”€ recording_id_loc.csv
          â”‚     â””â”€â”€ recording_id_loc_cleaned.csv
          â””â”€â”€ processed/
                â”œâ”€â”€ recording_id_processed_acc.csv
                â””â”€â”€ recording_id_processed_loc.csv
```

**Notes:**
- macOS system files (`__MACOSX/`, `.DS_Store`, `._*`) are automatically removed
- Structure validation is strict - all folders and files must be present

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file (optional for local development):

```bash
# Redis password (required for production)
REDIS_PASSWORD=your_password_here

# Execution mode (local or GPU instance)
USE_GPU_INSTANCE=false

# Flask environment
FLASK_ENV=production
```

**TTL**: 1 hour (auto-cleanup)

## ï¿½ Security

- **ZipSlip protection**: Validates file paths during extraction
- **Strict validation**: Enforces expected folder structure
- **File size limit**: 8 GB maximum
- **Allowed formats**: ZIP, TAR, TAR.GZ, TGZ
- **Automatic cleanup**: Removes partial uploads on validation failure
- **Redis authentication**: Required for production environments

## ï¿½ï¸ Technology Stack

- **Backend**: Flask 3.0, Gunicorn 21.2
- **Task Queue**: Celery 5.3, Redis 5.0
- **AWS**: boto3 1.34 (EC2, EFS)
- **SSH**: paramiko 3.3
- **Frontend**: Vanilla JavaScript (no framework)
- **UI Design**: Modern flat design with blue accent (#3b82f6)
